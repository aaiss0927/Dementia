import pandas as pd
import numpy as np
from sklearn.model_selection import LeaveOneOut # Leave-One-Out Cross-Validation
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
import os
from sklearn.base import clone
import joblib 

# ì‚¬ìš©í•  íŒŒì¼ ê²½ë¡œ ìƒìˆ˜ ì •ì˜
TRAIN_FILE_PATH = 'train_all.csv'
TEST_FILE_PATH = 'test_all.csv'
MODEL_FILE = 'final_model.joblib'
SCALER_FILE = 'final_scaler.joblib'
random_state = 96

def load_data(path, target_column='DIAG_NM'):
    """
    ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í”¼ì²˜(X)ì™€ íƒ€ê²Ÿ(y)ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        df = pd.read_csv(path)
    except FileNotFoundError as e:
        print(f"ì˜¤ë¥˜: íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return None, None
    
    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì‚­ì œ (Data Leakage ë°©ì§€ ë° ID/TOTAL ì‚­ì œ)
    # MMSE_NUMì€ data_splitter.pyì—ì„œ ì œì™¸ë˜ì—ˆì§€ë§Œ ì•ˆì „í•˜ê²Œ TOTALê³¼ í•¨ê»˜ í•œ ë²ˆ ë” ì œì™¸
    features_to_drop = ['SAMPLE_EMAIL', target_column, 'TOTAL', 'MMSE_NUM']
    
    X = df.drop(columns=[col for col in features_to_drop if col in df.columns])
    y = df[target_column]
    
    return X, y

def train_and_cross_validate(X_train, y_train, class_names):
    """
    Logistic Regression ëª¨ë¸ì„ LOOCVë¡œ í•™ìŠµí•˜ê³  í‰ê·  ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    print(f"\n--- Leave-One-Out Cross-Validation ({len(X_train)}-Fold) ì‹œì‘ ---")
    
    # LOOCV ê°ì²´ ìƒì„± (í´ë“œ ìˆ˜ = ì „ì²´ í•™ìŠµ ìƒ˜í”Œ ìˆ˜)
    loo = LeaveOneOut() 
    
    cv_accuracies = []
    dem_w = 1.1
    
    # ğŸ”¥ ëª¨ë¸ ì´ˆê¸°í™”: Dem(ì¹˜ë§¤)ì— ìˆ˜ë™ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ë¶€ì—¬ ğŸ”¥
    base_model = LogisticRegression(
        # multi_class='multinomial', 
        solver='lbfgs', 
        max_iter=100, 
        random_state=random_state, 
        class_weight={'CN': 1.0, 'Dem': dem_w} # CNì€ 0, Demì€ 1ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆë‹¤ê³  ê°€ì • (Demì— ë†’ì€ ê°€ì¤‘ì¹˜)
    )
    scaler = StandardScaler()
    
    # LOOCV ë£¨í”„
    # LOOCVëŠ” í´ë“œ ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ ì§„í–‰ ìƒí™©ì„ ì „ë¶€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    for fold, (train_index, val_index) in enumerate(loo.split(X_train, y_train)):
        
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í•  (ê²€ì¦ ë°ì´í„°ëŠ” í•­ìƒ 1ê°œ)
        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]
        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        X_fold_train_scaled = scaler.fit_transform(X_fold_train)
        X_fold_val_scaled = scaler.transform(X_fold_val)
        
        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        model = clone(base_model)
        model.fit(X_fold_train_scaled, y_fold_train)
        y_pred = model.predict(X_fold_val_scaled)
        
        # ì •í™•ë„ ê¸°ë¡
        accuracy = accuracy_score(y_fold_val, y_pred)
        cv_accuracies.append(accuracy)

    print(f"\n============= LOOCV í‰ê·  í‰ê°€ ê²°ê³¼ (ê°€ì¤‘ì¹˜: {dem_w}, ì‹œë“œ: {random_state}) =============")
    avg_accuracy = np.mean(cv_accuracies)
    print(f"LOOCV í‰ê·  ì •í™•ë„ (CV Mean Accuracy): {avg_accuracy:.4f}")
    print("==============================================================")
    
    # LOOCVëŠ” ëª¨ë¸ ì„ íƒë³´ë‹¤ ì„±ëŠ¥ ì¶”ì •ì— ì¤‘ì ì„ ë‘ë¯€ë¡œ, 
    # ì „ì²´ í›ˆë ¨ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    X_train_final_scaled = scaler.fit_transform(X_train)
    final_model = clone(base_model)
    final_model.fit(X_train_final_scaled, y_train)

    # ğŸ”¥ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ğŸ”¥
    joblib.dump(final_model, MODEL_FILE)
    joblib.dump(scaler, SCALER_FILE)
    print(f"âœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: {MODEL_FILE}, {SCALER_FILE}")
    
    return final_model, scaler, class_names


def evaluate_final_test(final_model, scaler, X_test, y_test, class_names):
    """
    ìµœì¢… í›ˆë ¨ëœ ëª¨ë¸ì„ ë…ë¦½ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
    """
    print("\n--- ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ì‹œì‘ ---")
    
    X_test_scaled = scaler.transform(X_test)
    y_pred = final_model.predict(X_test_scaled)

    print("\n============= ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼ =============")
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ (Test Accuracy): {accuracy:.4f}")
    
    report = classification_report(y_test, y_pred, target_names=class_names, zero_division=0)
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(report)
    print("==============================================")


if __name__ == '__main__':
    # Step 1: ë°ì´í„° ë¡œë“œ
    X_train_raw, y_train = load_data(TRAIN_FILE_PATH)
    X_test_raw, y_test = load_data(TEST_FILE_PATH)
    
    if X_train_raw is not None and X_test_raw is not None:
        
        # ë ˆì´ë¸” ì¸ì½”ë”©
        le = LabelEncoder()
        # y_trainê³¼ y_testëŠ” ì´ë¯¸ CN/Demë§Œ ì¡´ì¬
        y_train_encoded = le.fit_transform(y_train)
        y_test_encoded = le.transform(y_test)
        class_names = le.classes_
        print(f"ë ˆì´ë¸” ë§¤í•‘: {dict(zip(le.transform(class_names), class_names))}")

        # Step 2: LOOCV ìˆ˜í–‰
        final_model, final_scaler, _ = train_and_cross_validate(X_train_raw, y_train, class_names)

        # Step 3: ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
        evaluate_final_test(final_model, final_scaler, X_test_raw, y_test, class_names)