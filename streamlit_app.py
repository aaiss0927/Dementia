import streamlit as st
import pandas as pd
import numpy as np
import datetime
import re
import joblib
import requests
import os
from openai import OpenAI
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import base64
import io
import warnings
import random

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
warnings.filterwarnings('ignore')

# --- 0. ì „ì—­ ì„¤ì • ë° API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
try:
    # st.secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    client = OpenAI(api_key=st.secrets.get("openai_api_key"))
except Exception:
    client = None

# ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œ
MODEL_FILE = 'final_model.joblib'
SCALER_FILE = 'final_scaler.joblib'
RANDOM_STATE = 42

# --- 1. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”© ---
@st.cache_resource
def load_model_and_scaler():
    """ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•˜ê±°ë‚˜, íŒŒì¼ì´ ì—†ì„ ê²½ìš° ë”ë¯¸ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        model = joblib.load(MODEL_FILE)
        scaler = joblib.load(SCALER_FILE)
        st.success("âœ… ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ.")
        return model, scaler
    except FileNotFoundError:
        class DummyModel:
            def predict(self, X): return np.array([random.choice(['Dem', 'CN'])])
            def predict_proba(self, X): return np.array([[0.5, 0.5]])
        class DummyScaler:
            def transform(self, X): return X
        st.error("âš ï¸ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ. ë”ë¯¸ ëª¨ë¸ ì‚¬ìš©.")
        return DummyModel(), DummyScaler()

model, scaler = load_model_and_scaler()

# --- 2. ì±„ì  ë¡œì§ í•¨ìˆ˜ ---

def get_current_korean_season(month):
    """í˜„ì¬ ì›”ì— ë”°ë¥¸ í•œêµ­ ê³„ì ˆ ë°˜í™˜ (ê°„ì†Œí™”)"""
    if month in [3, 4, 5]: return "ë´„"
    elif month in [6, 7, 8]: return "ì—¬ë¦„"
    elif month in [9, 10, 11]: return "ê°€ì„"
    else: return "ê²¨ìš¸"

def score_time_date(q_num, user_input, current_dt):
    """Q01 ~ Q05 ì‹œê°„/ë‚ ì§œ ì§€ë‚¨ë ¥ ì±„ì  ë¡œì§"""
    score = 0
    if q_num == 1 and user_input == str(current_dt.year): score = 1
    elif q_num == 2 and user_input == get_current_korean_season(current_dt.month): score = 1
    elif q_num == 3 and user_input == str(current_dt.day): score = 1
    elif q_num == 4:
        korean_day = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"][current_dt.weekday()]
        if user_input == korean_day: score = 1
    elif q_num == 5 and user_input == str(current_dt.month): score = 1
    return score

@st.cache_data
def get_user_location():
    """ê³µê°œ IP ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ìœ„ì¹˜ (êµ­ê°€, ë„ì‹œ)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        ip_response = requests.get('https://api.ipify.org?format=json')
        public_ip = ip_response.json()['ip']
        location_response = requests.get(f'https://ipapi.co/{public_ip}/json/')
        data = location_response.json()
        country = "ëŒ€í•œë¯¼êµ­" if data.get('country_code') == 'KR' else data.get('country_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        city = data.get('city', 'ì•Œ ìˆ˜ ì—†ìŒ')
        return country, city
    except Exception:
        return "ì•Œ ìˆ˜ ì—†ìŒ", "ì•Œ ìˆ˜ ì—†ìŒ"

def score_stt_response(audio_file_object, target_keywords=None, model_to_use="whisper-1"):
    """OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ UploadedFile ê°ì²´ë¥¼ ì§ì ‘ ì „ì†¡í•˜ì—¬ ì±„ì í•©ë‹ˆë‹¤."""
    if client is None: return 0, "STT API í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜"
    if audio_file_object is None: return 0, "STT: ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì²´ ë¶€ì¬"
    
    try:
        transcript = client.audio.transcriptions.create(
            model=model_to_use, 
            file=audio_file_object, 
            language="ko"
        ).text.lower()
            
        if target_keywords: 
            if any(keyword.lower() in transcript for keyword in target_keywords): score = 1
            else: score = 0
            return score, transcript
        else:
            return 1, transcript
        
    except Exception as e:
        return 0, f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}"

def score_llm_writing(writing_text):
    """OpenAI GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¸€ì“°ê¸° ì ìˆ˜(0 ë˜ëŠ” 1)ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. (Q19)"""
    if client is None or not writing_text: return 0
    system_prompt = ("ë‹¹ì‹ ì€ ì¸ì§€ ê¸°ëŠ¥ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ê¸€ì´ ì£¼ì–´ì§„ ì£¼ì œ('ë‚ ì”¨ ë˜ëŠ” ê¸°ë¶„')ì— ëŒ€í•´ 'í•˜ë‚˜ì˜ ì˜¨ì „í•œ ë¬¸ì¥'ì¸ì§€ íŒë‹¨í•˜ê³ , "
                    "ì˜¨ì „í•œ ë¬¸ì¥ì´ë©´ '1', ì•„ë‹ˆë©´ '0'ì„ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.")
    
    try:
        response = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": f"ì‚¬ìš©ì ê¸€: '{writing_text}'"}], temperature=0)
        score_match = re.search(r'[01]', response.choices[0].message.content)
        return int(score_match.group(0)) if score_match else 0
    except Exception:
        return 0

def score_drawing_similarity(original_image_url, user_drawing_data_url):
    """Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ Q17 ê·¸ë¦¼ ì±„ì """
    if client is None: return 0, "Vision API í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜"
    if not user_drawing_data_url: return 0, "ê·¸ë¦° ê·¸ë¦¼ ë°ì´í„° ì—†ìŒ"

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": "ì²« ë²ˆì§¸ ê·¸ë¦¼(ì›ë³¸)ì„ ë‘ ë²ˆì§¸ ê·¸ë¦¼(ì‚¬ìš©ìê°€ ê·¸ë¦° ê·¸ë¦¼)ì´ ì–¼ë§ˆë‚˜ ì˜ ëª¨ì‚¬í–ˆëŠ”ì§€ í‰ê°€í•˜ê³ , '1' (ë§¤ìš° ìœ ì‚¬) ë˜ëŠ” '0' (ìœ ì‚¬í•˜ì§€ ì•ŠìŒ)ìœ¼ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”."},
                    {"type": "image_url", "image_url": {"url": original_image_url, "detail": "low"}},
                    {"type": "image_url", "image_url": {"url": user_drawing_data_url, "detail": "low"}},
                ]},
            ],
            max_tokens=1,
            temperature=0,
        )
        score_match = re.search(r'[01]', response.choices[0].message.content)
        return int(score_match.group(0)) if score_match else 0, "Vision API í‰ê°€ ì™„ë£Œ"
    except Exception as e:
        return 0, f"Vision API ì²˜ë¦¬ ì˜¤ë¥˜: {e}"

def score_registration_recall(user_input, target_words):
    """Q11, Q13 ë‹¨ì–´ ë“±ë¡/íšŒìƒ ì±„ì """
    user_words = set(re.findall(r'\b\w+\b', user_input.replace(',', ' ').lower()))
    target_set = set(target_words)
    return 1 if target_set.issubset(user_words) else 0

# --- 3. Streamlit UI êµ¬ì„± ---

def app():
    st.set_page_config(page_title="MMSE ê°„ì´ ìê°€ ì§„ë‹¨ ì›¹ì‚¬ì´íŠ¸", layout="wide")
    st.title("ğŸ§  MMSE ê¸°ë°˜ ê°„ì´ ìê°€ ì§„ë‹¨ (ìµœì¢… í†µí•© ë²„ì „)")
    st.markdown("---")
    
    current_dt = datetime.datetime.now()
    user_country, user_city = get_user_location()
    target_words = {"ì‚¬ê³¼", "ì„¸íƒê¸°", "ì±…ìƒ"}
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'features' not in st.session_state:
        st.session_state.features = {k: 0 for k in ['Q01', 'Q02', 'Q03', 'Q04', 'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11_1', 'Q11_2', 'Q11_3', 'Q12_1', 'Q12_2', 'Q12_3', 'Q12_4', 'Q12_5', 'Q13_1', 'Q13_2', 'Q13_3', 'Q14_1', 'Q14_2', 'Q15', 'Q16_1', 'Q16_2', 'Q16_3', 'Q17', 'Q18', 'Q19']}
        st.session_state.basic_info = {'SAMPLE_EMAIL': '', 'DIAG_SEQ': 1, 'MMSE_KIND': 2}
        st.session_state.q15_audio_file = None 
        st.session_state.q18_audio_file = None
        st.session_state.q17_drawing_data_url = None

    # --- ë©”ì¸ í¼ ì„¹ì…˜ (ëª¨ë“  ì…ë ¥ ìœ„ì ¯ í¬í•¨) ---
    with st.form(key='diagnosis_form'):
        
        # --- ê¸°ë³¸ ì •ë³´ ---
        st.header("ğŸ‘¤ ê¸°ë³¸ ì •ë³´")
        col1, col2 = st.columns(2)
        with col1:
            email = st.text_input("SAMPLE_EMAIL", key='email_input')
            st.session_state.basic_info['SAMPLE_EMAIL'] = email
        with col2:
            st.text_input("DIAG_SEQ", value="1", disabled=True)
            st.text_input("MMSE_KIND", value="2 (ê³ ì •)", disabled=True)
        st.markdown("---")
        
        # --- Q01~Q19 ì…ë ¥ í•„ë“œ ---
        
        # Q01~Q10 (ì§€ë‚¨ë ¥)
        st.header("ğŸ•°ï¸ ì§€ë‚¨ë ¥")
        q_cols = st.columns(5)
        st.session_state.features['Q01'] = score_time_date(1, q_cols[0].text_input("Q01: ì—°ë„", key='q01'), current_dt)
        st.session_state.features['Q02'] = score_time_date(2, q_cols[1].text_input("Q02: ê³„ì ˆ", key='q02'), current_dt)
        st.session_state.features['Q03'] = score_time_date(3, q_cols[2].text_input("Q03: ì¼", key='q03'), current_dt)
        st.session_state.features['Q04'] = score_time_date(4, q_cols[3].text_input("Q04: ìš”ì¼", key='q04'), current_dt)
        st.session_state.features['Q05'] = score_time_date(5, q_cols[4].text_input("Q05: ì›”", key='q05'), current_dt)
        
        st.markdown("##### ì¥ì†Œ")
        q_cols = st.columns(5)
        st.session_state.features['Q06'] = 1 if q_cols[0].text_input(f"Q06: êµ­ê°€ ({user_country})", key='q06') == user_country else 0
        st.session_state.features['Q07'] = 1 if q_cols[1].text_input(f"Q07: ë„ì‹œ ({user_city})", key='q07') == user_city else 0
        st.session_state.features['Q08'] = 1 if q_cols[2].text_input("Q08: ê±´ë¬¼ ìœ í˜•", key='q08') else 0
        st.session_state.features['Q09'] = 1 if q_cols[3].text_input("Q09: ê±´ë¬¼ ì´ë¦„", key='q09') else 0
        st.session_state.features['Q10'] = 1 if q_cols[4].text_input("Q10: ì¸µìˆ˜", key='q10') else 0
        st.markdown("---")
        
        # Q11, Q13 ë“±ë¡/íšŒìƒ
        st.header("ğŸ ê¸°ì–µ")
        q11_input = st.text_input("Q11: ì„¸ ê°€ì§€ ë¬¼ê±´ ì´ë¦„ì„ ë”°ë¼ ë§í•˜ì„¸ìš”.", key='q11_input')
        q11_score = score_registration_recall(q11_input, target_words)
        st.session_state.features['Q11_1'] = st.session_state.features['Q11_2'] = st.session_state.features['Q11_3'] = q11_score
        
        q13_input = st.text_input("Q13: ì•„ê¹Œ ì™¸ìš´ ë‹¨ì–´ ì„¸ ê°€ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", key='q13_input')
        q13_score = score_registration_recall(q13_input, target_words)
        st.session_state.features['Q13_1'] = st.session_state.features['Q13_2'] = st.session_state.features['Q13_3'] = q13_score
        st.markdown("---")

        # Q12 (ê³„ì‚°)
        st.header("ğŸ”¢ ê³„ì‚°")
        q12_answers = [93, 86, 79, 72, 65]
        q12_cols = st.columns(5)
        for i, answer in enumerate(q12_answers):
            with q12_cols[i]:
                q12_input = st.number_input(f"Q12_{i+1}", key=f'q12_{i+1}', step=1, value=None, format="%d")
                score = 1 if q12_input and int(q12_input) == answer else 0
                st.session_state.features[f'Q12_{i+1}'] = score
        st.markdown("---")
        
        # Q15, Q18 íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (STT ì˜¤ë¥˜ ë°©ì§€ ë° í¼ ë‚´ë¶€)
        st.header("ğŸ¤ STT ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ")
        st.info("Q15/Q18 ì ìˆ˜ë¥¼ ë°›ìœ¼ë ¤ë©´ **.wav, .mp3, .m4a** íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. íŒŒì¼ì´ ì—†ìœ¼ë©´ 0ì  ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        
        col_q15, col_q18 = st.columns(2)
        with col_q15:
            st.subheader("Q15: ë”°ë¼ ë§í•˜ê¸°")
            st.caption("'_ê°„ì¥ ê³µì¥ ê³µì¥ì¥_'ì„ ë…¹ìŒí•œ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
            q15_uploaded_file = st.file_uploader("Q15 ì˜¤ë””ì˜¤ íŒŒì¼", type=['wav', 'mp3', 'm4a'], key="uploader_q15")
            st.session_state.q15_audio_file = q15_uploaded_file
        with col_q18:
            st.subheader("Q18: ë¬¸ì¥ ì½ê³  ìˆ˜í–‰")
            st.caption("'_ëˆˆì„ ê°ìœ¼ì„¸ìš”_'ë¥¼ ì½ì€ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
            q18_uploaded_file = st.file_uploader("Q18 ì˜¤ë””ì˜¤ íŒŒì¼", type=['wav', 'mp3', 'm4a'], key="uploader_q18")
            st.session_state.q18_audio_file = q18_uploaded_file
        st.markdown("---")

        # Q14 (ì´ë¦„ ëŒ€ê¸°)
        st.header("ğŸ—£ï¸ ì–¸ì–´ ë° ì‹¤í–‰ ëŠ¥ë ¥")
        st.subheader("Q14: ì´ë¦„ ëŒ€ê¸°")
        st.image("https://i.imgur.com/vH0k1tM.png", caption="ì›ë³¸ ì´ë¯¸ì§€: ì‹œê³„", width=100) 
        q14_1 = st.text_input("Q14_1: ë¬´ì—‡ì…ë‹ˆê¹Œ?", key='q14_1')
        st.session_state.features['Q14_1'] = 1 if 'ì‹œê³„' in q14_1 else 0
        
        st.image("https://i.imgur.com/kS5x0N9.png", caption="ì›ë³¸ ì´ë¯¸ì§€: ì—°í•„", width=100) 
        q14_2 = st.text_input("Q14_2: ë¬´ì—‡ì…ë‹ˆê¹Œ?", key='q14_2')
        st.session_state.features['Q14_2'] = 1 if 'ì—°í•„' in q14_2 else 0

        # Q16 (3ë‹¨ê³„ ëª…ë ¹)
        st.subheader("Q16: 3ë‹¨ê³„ ëª…ë ¹ ìˆ˜í–‰ (ì²´í¬ ì‹œ ìˆ˜í–‰ ì„±ê³µìœ¼ë¡œ ê°€ì •)")
        q16_1 = st.checkbox("Q16_1: ì¢…ì´ë¥¼ ë’¤ì§‘ì—ˆìŠµë‹ˆë‹¤.", key='q16_1')
        q16_2 = st.checkbox("Q16_2: ë°˜ìœ¼ë¡œ ì ‘ì—ˆìŠµë‹ˆë‹¤.", key='q16_2')
        q16_3 = st.checkbox("Q16_3: ì €ì—ê²Œ ì£¼ì—ˆìŠµë‹ˆë‹¤.", key='q16_3')
        st.session_state.features['Q16_1'] = 1 if q16_1 else 0
        st.session_state.features['Q16_2'] = 1 if q16_2 else 0
        st.session_state.features['Q16_3'] = 1 if q16_3 else 0

        # Q17 (ë”°ë¼ ê·¸ë¦¬ê¸° - Canvas + Vision API)
        st.subheader("Q17: ë”°ë¼ ê·¸ë¦¬ê¸°")
        q17_original_image_url = "https://i.imgur.com/gK9p5Fz.png"
        st.image(q17_original_image_url, caption="ì›ë³¸ ê·¸ë¦¼: ì˜¤ê°í˜•ê³¼ ì‚¬ê°í˜•", width=150)
        canvas_result = st_canvas(stroke_width=3, stroke_color="#000000", width=250, height=250, drawing_mode="freedraw", key="canvas")

        # Q17 Drawing Data URL ì €ì¥ ë¡œì§
        if canvas_result.image_data is not None:
            image_array = canvas_result.image_data
            if image_array.size > 0:
                # NumPy ë°°ì—´ì„ PIL Image ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ Data URL ìƒì„±
                pil_image = Image.fromarray(image_array.astype('uint8'), 'RGBA')
                buffered = io.BytesIO()
                pil_image.save(buffered, format="PNG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                st.session_state.q17_drawing_data_url = f"data:image/png;base64,{img_str}"
            else:
                 st.session_state.q17_drawing_data_url = None
        else:
             st.session_state.q17_drawing_data_url = None
        
        # Q19 (ê¸€ì“°ê¸° - LLM ì±„ì )
        st.subheader("Q19: ë¬¸ì¥ ë§Œë“¤ê¸°")
        q19_text = st.text_area("Q19: ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”.", key='q19_text_area', placeholder="ë‚ ì”¨ë‚˜ ê¸°ë¶„ì— ëŒ€í•œ ì˜¨ì „í•œ ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.")
        
        # --- ì œì¶œ ë²„íŠ¼ (í¼ ì „ìš©) ---
        st.markdown("---")
        submit_button = st.form_submit_button(label='ìê°€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸ ë° ì˜ˆì¸¡')

    # --- 4. ì œì¶œ ë° ì˜ˆì¸¡ (submit_button í´ë¦­ ì‹œ ì‹¤í–‰) ---
    if submit_button:
        
        # 1. LLM ë° Vision API ìµœì¢… ì±„ì 
        q19_score = score_llm_writing(q19_text)
        st.session_state.features['Q19'] = q19_score
        
        q17_original_image_url = "https://i.imgur.com/gK9p5Fz.png"
        q17_score, q17_vision_status = 0, "ê·¸ë¦° ê·¸ë¦¼ ì—†ìŒ"
        if st.session_state.q17_drawing_data_url:
            q17_score, q17_vision_status = score_drawing_similarity(q17_original_image_url, st.session_state.q17_drawing_data_url)
        st.session_state.features['Q17'] = q17_score
        
        # 2. STT ìµœì¢… ì±„ì  (Q15, Q18) - UploadedFile ê°ì²´ë¥¼ ì§ì ‘ ì „ë‹¬
        
        # Q15 ì²˜ë¦¬
        q15_score, q15_transcript = 0, "íŒŒì¼ ì—†ìŒ"
        if st.session_state.q15_audio_file:
            q15_score, q15_transcript = score_stt_response(st.session_state.q15_audio_file, target_keywords=None)
        st.session_state.features['Q15'] = q15_score
        
        # Q18 ì²˜ë¦¬
        q18_score, q18_transcript = 0, "íŒŒì¼ ì—†ìŒ"
        if st.session_state.q18_audio_file:
            q18_score, q18_transcript = score_stt_response(st.session_state.q18_audio_file, target_keywords=["ëˆˆì„ ê°ìœ¼ì„¸ìš”"]) 
        st.session_state.features['Q18'] = q18_score

        # 3. ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ë° ì˜ˆì¸¡
        features_for_model = {**st.session_state.basic_info, **st.session_state.features}
        features_for_model.pop('SAMPLE_EMAIL')
        
        feature_order = [
            'DIAG_SEQ', 'MMSE_KIND', 'Q01', 'Q02', 'Q03', 'Q04', 'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10',
            'Q11_1', 'Q11_2', 'Q11_3', 'Q12_1', 'Q12_2', 'Q12_3', 'Q12_4', 'Q12_5', 'Q13_1', 'Q13_2', 'Q13_3',
            'Q14_1', 'Q14_2', 'Q15', 'Q16_1', 'Q16_2', 'Q16_3', 'Q17', 'Q18', 'Q19'
        ]
        
        input_data = {k: features_for_model[k] for k in feature_order}
        input_df = pd.DataFrame([input_data])

        # ì˜ˆì¸¡ ìˆ˜í–‰
        if model is not None and scaler is not None:
            input_scaled = scaler.transform(input_df)
            prediction = model.predict(input_scaled)
            result_text = "Dem (ì¹˜ë§¤/ìœ„í—˜êµ°)" if prediction[0] == 'Dem' else "CN (ì •ìƒ)"
        else:
            result_text = "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"

        st.subheader("âœ… ìê°€ ì§„ë‹¨ ê²°ê³¼")
        if "Dem" in result_text:
            st.error(f"**ì§„ë‹¨ ê²°ê³¼:** {result_text}")
            st.warning("âš ï¸ ì´ ê²°ê³¼ëŠ” ì¹˜ë§¤ ìœ„í—˜êµ°(MCI/Dem)ìœ¼ë¡œ ë¶„ë¥˜ëœ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤. ì „ë¬¸ì˜ì˜ ì§„ë£Œë¥¼ ë°˜ë“œì‹œ ë°›ìœ¼ì‹­ì‹œì˜¤.")
        elif "CN" in result_text:
            st.success(f"**ì§„ë‹¨ ê²°ê³¼:** {result_text}")
            st.info("ì´ ê²°ê³¼ëŠ” ê°„ì´ ì§„ë‹¨ì´ë©°, ì •ê¸°ì ì¸ ê²€ì§„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.error(result_text)
        
        st.subheader("ğŸ“Š ì±„ì  ê²°ê³¼ ìš”ì•½")
        total_score = input_df.iloc[0].drop(['DIAG_SEQ', 'MMSE_KIND']).sum()
        st.metric(label="ì´ ì ìˆ˜ (Max 26ì )", value=f"{total_score}ì ")
        
        st.caption(f"Q15 (ë”°ë¼ ë§í•˜ê¸°) ì±„ì : {q15_score}ì  (STT ì „ì‚¬: {q15_transcript[:50]}...)")
        st.caption(f"Q18 (ì½ê³  ìˆ˜í–‰) ì±„ì : {q18_score}ì  (STT ì „ì‚¬: {q18_transcript[:50]}...)")
        st.caption(f"Q17 (ë”°ë¼ ê·¸ë¦¬ê¸°) ì±„ì : {q17_score}ì  ({q17_vision_status})")
        st.caption(f"Q19 (ê¸€ì“°ê¸°) ì±„ì : {q19_score}ì  (LLM íŒì •)")
        
        st.dataframe(input_df.T.rename(columns={0: 'ì…ë ¥ í”¼ì²˜ ê°’'}), use_container_width=True)


if __name__ == "__main__":
    from PIL import Image
    import io
    app()